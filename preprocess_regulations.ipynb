{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import chdir, getcwd, listdir, mkdir\n",
    "from os.path import join\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import pkg_resources\n",
    "\n",
    "HOME = getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_list = [pkg for pkg in pkg_resources.working_set]\n",
    "\n",
    "if 'googletrans' not in [pkg.key for pkg in package_list]:\n",
    "    ! pip install googletrans==3.1.0a0\n",
    "import googletrans\n",
    "    \n",
    "if 'pdfplumber' not in [pkg.key for pkg in package_list]:\n",
    "    ! pip install pdfplumber\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAR Part 121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download file from the ECFR website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.govinfo.gov/bulkdata/ECFR/title-14/ECFR-title14.xml'\n",
    "\n",
    "if 'Regulations' not in listdir():\n",
    "    mkdir('Regulations')\n",
    "\n",
    "chdir(join(HOME, 'Regulations'))\n",
    "r = requests.get(URL)\n",
    "with open('ECFR-title14.xml', 'wb') as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "chdir(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify node corresponding to Part 121 xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join('Regulations', 'ECFR-title14.xml')\n",
    "tree = ET.parse(filepath)\n",
    "root = tree.getroot()\n",
    "\n",
    "for element in root.iter():\n",
    "    if element.tag == 'DIV5':\n",
    "        if element.attrib['N'] == '121':\n",
    "            root121 = element\n",
    "\n",
    "section_nodes = []\n",
    "\n",
    "for element in root121.iter():\n",
    "    if element.tag == 'DIV8':\n",
    "        section_nodes.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save file with individual sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "sections = []\n",
    "\n",
    "for section in section_nodes:\n",
    "    titles.append(section.attrib['N'])\n",
    "    text = ''\n",
    "    for line in section.itertext():\n",
    "        if re.search('\\w', line):\n",
    "            text += line\n",
    "    sections.append(text)\n",
    "    \n",
    "filename = join(HOME, 'Regulations', 'FAR_Part121_sections.xlsx')    \n",
    "pd.DataFrame({'title':titles, 'requirement':sections}).to_excel(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test splitting method: print section to screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_NUMBER = 155\n",
    "\n",
    "section, paragraph, item = '', '', ''\n",
    "section_id, paragraph_id, item_id = '', '', ''\n",
    "current_level = ''\n",
    "\n",
    "for line in section_nodes[SECTION_NUMBER].itertext():\n",
    "    if re.match('^ยง 121.\\d*', line):\n",
    "        current_level = 'section'\n",
    "        section_id = re.findall('^ยง 121.\\d*', line)[0]\n",
    "        section = line + '\\n'\n",
    "        paragraph, item, paragraph_id, item_id = '', '', '', ''\n",
    "    elif re.match('^\\([a-h]\\)', line):\n",
    "        if current_level == 'paragraph' or current_level == 'item':\n",
    "            print(section_id + paragraph_id + item_id + '\\n')\n",
    "            print(section + paragraph + item)\n",
    "            print('----------')\n",
    "        paragraph_id = re.findall('^\\([a-h]\\)', line)[0]\n",
    "        paragraph = line\n",
    "        item, item_id = '', ''\n",
    "        current_level = 'paragraph'\n",
    "    elif re.match('^\\(\\d*\\)',line):\n",
    "        if current_level == 'item':\n",
    "            print(section_id + paragraph_id + item_id + '\\n')\n",
    "            print(section + paragraph + item)\n",
    "            print('----------')\n",
    "        item_id = re.findall('^\\(\\d*\\)',line)[0]\n",
    "        item = line\n",
    "        current_level = 'item'\n",
    "    elif re.match('^\\s+$', line):\n",
    "        pass\n",
    "    elif re.match('\\[.*\\]', line):\n",
    "        pass\n",
    "    else:\n",
    "        if current_level == 'section':\n",
    "            section += line\n",
    "        elif current_level == 'paragraph':\n",
    "            paragraph += line\n",
    "        elif current_level == 'item':\n",
    "            item += line\n",
    "print(section_id + paragraph_id + item_id + '\\n')\n",
    "print(section + paragraph + item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of titles and requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement_titles = []\n",
    "requirement_texts = []\n",
    "\n",
    "for sec in section_nodes:\n",
    "    \n",
    "    section, paragraph, item = '', '', ''\n",
    "    section_id, paragraph_id, item_id = '', '', ''\n",
    "    current_level = ''\n",
    "\n",
    "    for line in sec.itertext():\n",
    "        if re.match('^ยง 121.\\d*', line):\n",
    "            current_level = 'section'\n",
    "            section_id = re.findall('^ยง 121.\\d*', line)[0]\n",
    "            section = line + '\\n'\n",
    "            paragraph, item, paragraph_id, item_id = '', '', '', ''\n",
    "        elif re.match('^\\([a-h]\\)', line):\n",
    "            if current_level == 'paragraph' or current_level == 'item':\n",
    "                requirement_titles.append(section_id + paragraph_id + item_id)\n",
    "                requirement_texts.append(section + paragraph + item)\n",
    "            paragraph_id = re.findall('^\\([a-h]\\)', line)[0]\n",
    "            paragraph = line\n",
    "            item, item_id = '', ''\n",
    "            current_level = 'paragraph'\n",
    "        elif re.match('^\\(\\d*\\)',line):\n",
    "            if current_level == 'item':\n",
    "                requirement_titles.append(section_id + paragraph_id + item_id)\n",
    "                requirement_texts.append(section + paragraph + item)\n",
    "            item_id = re.findall('^\\(\\d*\\)',line)[0]\n",
    "            item = line\n",
    "            current_level = 'item'\n",
    "        elif re.match('^\\s+$', line):\n",
    "            pass\n",
    "        elif re.match('\\[.*\\]', line):\n",
    "            pass\n",
    "        else:\n",
    "            if current_level == 'section':\n",
    "                section += line\n",
    "            elif current_level == 'paragraph':\n",
    "                paragraph += line\n",
    "            elif current_level == 'item':\n",
    "                item += line\n",
    "    requirement_titles.append(section_id + paragraph_id + item_id)\n",
    "    requirement_texts.append(section + paragraph + item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save excel file to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join(HOME, 'Regulations', 'FAR_Part121_nodes.xlsx')\n",
    "df = pd.DataFrame(zip(requirement_titles, requirement_texts), columns = ['title', 'requirement'])\n",
    "df = df.loc[df.title != '']\n",
    "df.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBAC 121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pdf file from www.ANAC.gov.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.anac.gov.br/assuntos/legislacao/legislacao-1/rbha-e-rbac/rbac/rbac-121/@@display-file/arquivo_norma/RBAC121EMD12.pdf'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "if 'Regulations' not in listdir():\n",
    "    mkdir('Regulations')\n",
    "\n",
    "chdir(join(HOME, 'Regulations'))\n",
    "\n",
    "with open('RBAC121.pdf', 'wb') as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "chdir(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the .pdf file and save to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join(HOME, 'Regulations', 'RBAC121.pdf')\n",
    "text = ''\n",
    "chdir(HOME)\n",
    "\n",
    "with pdfplumber.open(filepath) as pdf:\n",
    "    #for page in range(len(pdf.pages)):\n",
    "    for page in range(9,243): # skip the table of contents and stop before annexes\n",
    "        text += pdf.pages[page].extract_text()\n",
    "        \n",
    "filepath = join(HOME, 'Regulations', 'RBAC121.txt')\n",
    "with open(filepath, 'w') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save version with individual sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list of individual sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join(HOME, 'Regulations', 'RBAC121.txt')\n",
    "\n",
    "requirements = []\n",
    "titles = []\n",
    "\n",
    "with open(filepath) as file:\n",
    "    for line in file:\n",
    "        if (re.match(' Data da emissรฃo', line) or \n",
    "            re.match('Data de vigรชncia', line) or \n",
    "            re.match('Origem: SPO', line) or\n",
    "            #re.match('SUBPARTE ', line) or\n",
    "            #re.match('\\[RESERVADO\\]', line) or\n",
    "            not re.search('\\w', line)):\n",
    "            pass\n",
    "        elif re.match('^121\\.\\d{1,4}  ', line):\n",
    "            requirements.append(line)\n",
    "        elif len(requirements) > 0:\n",
    "            requirements[-1] += line\n",
    "            \n",
    "for n, req in enumerate(requirements):\n",
    "    #titles.append(re.findall('121.\\d{1,4}', req)[0]) # alternative implementation\n",
    "    titles.append(req.split('  ')[0])\n",
    "    requirements[n] = re.sub('\\nSUBPARTE \\w*\\s\\n.*$', '', req, flags = re.DOTALL)\n",
    "    \n",
    "filepath = join(HOME, 'Regulations', 'RBAC121_sections.xlsx')    \n",
    "pd.DataFrame({'title':titles, 'requirement':requirements}).to_excel(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save split version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split sections into paragraphs and items and save to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join(HOME, 'Regulations', 'RBAC121_sections.xlsx')\n",
    "df_sections = pd.read_excel(filepath, dtype=str)[['title', 'requirement']]\n",
    "\n",
    "section_titles, section_texts = [], []\n",
    "item_titles, item_texts = [], []\n",
    "\n",
    "\n",
    "for section_tuple in df_sections.itertuples():\n",
    "    sec = section_tuple[1]\n",
    "    req = section_tuple[2]\n",
    "    section, paragraph, item = '', '', ''\n",
    "    section_id, paragraph_id, item_id = '', '', ''\n",
    "    current_level = ''\n",
    "    \n",
    "    for line in req.split('\\n'):\n",
    "        if re.match('^121.\\d*', line) and re.match(req.split(' ')[0], line):\n",
    "            current_level = 'section'\n",
    "            section_id = re.findall('^121.\\d*', line)[0]\n",
    "            section = line + '\\n'\n",
    "            paragraph, item, paragraph_id, item_id = '', '', '', ''\n",
    "        elif re.match('^\\([a-h]\\)', line):\n",
    "            if current_level == 'paragraph' or current_level == 'item':\n",
    "                section_titles.append(section_id + paragraph_id + item_id)\n",
    "                section_texts.append(section + paragraph + item)\n",
    "            paragraph_id = re.findall('^\\([a-h]\\)', line)[0]\n",
    "            paragraph = line\n",
    "            item, item_id = '', ''\n",
    "            current_level = 'paragraph'\n",
    "        elif re.match('^\\(\\d*\\)',line):\n",
    "            if current_level == 'item':\n",
    "                section_titles.append(section_id + paragraph_id + item_id)\n",
    "                section_texts.append(section + paragraph + item)\n",
    "            item_id = re.findall('^\\(\\d*\\)',line)[0]\n",
    "            item = line\n",
    "            current_level = 'item'\n",
    "        elif re.match('^\\s+$', line):\n",
    "            pass\n",
    "        elif re.match('\\[.*\\]', line):\n",
    "            pass\n",
    "        else:\n",
    "            if current_level == 'section':\n",
    "                section += line\n",
    "            elif current_level == 'paragraph':\n",
    "                paragraph += line\n",
    "            elif current_level == 'item':\n",
    "                item += line\n",
    "    section_titles.append(section_id + paragraph_id + item_id)\n",
    "    section_texts.append(section + paragraph + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join(HOME, 'Regulations', 'RBAC121_nodes.xlsx')\n",
    "df_nodes = pd.DataFrame({'title':section_titles, 'requirement':section_texts})\n",
    "df_nodes.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists containing each section translation and translation status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = join(HOME, 'Regulations', 'RBAC121_sections.xlsx')\n",
    "requirements = pd.read_excel(filepath)['requirement'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBAC121_lang = np.repeat(np.array('pt'), len(requirements)).tolist()\n",
    "RBAC121_en = np.repeat(np.array(''), len(requirements)).tolist()\n",
    "RBAC121_extra_data = np.repeat(np.array(''), len(requirements)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate each section using the google translate service. Run this code every few hours until all sentences are translated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = googletrans.Translator()\n",
    "wait_delay = 2 * 60 * 60 # 1 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated sentences: 0 out of 360\n",
      "Translated sentences: 132 out of 360\n",
      "Translated sentences: 259 out of 360\n",
      "Translated sentences: 358 out of 360\n",
      "Translated sentences: 358 out of 360\n"
     ]
    }
   ],
   "source": [
    "wait_bool = False\n",
    "translation_ready = 'RBAC121_sections_en.xlsx' in listdir(join(HOME, 'Regulations'))\n",
    "\n",
    "while translation_ready != True:\n",
    "    \n",
    "    if wait_bool: # do not wait on the first time\n",
    "        time.sleep(wait_delay)\n",
    "    wait_bool=True\n",
    "    \n",
    "    for section in range(len(requirements)):\n",
    "        if RBAC121_lang[section] == 'pt':\n",
    "            translation = translator.translate(requirements[section], dest='en', src='pt')\n",
    "            RBAC121_en[section] = translation.text\n",
    "            RBAC121_extra_data[section] = translation.extra_data\n",
    "            if translation.extra_data['original-language'] == 'pt':\n",
    "                RBAC121_lang[section] = 'en'\n",
    "\n",
    "    print('Translated sentences: {} out of {}'.format(RBAC121_lang.count('en'), len(RBAC121_lang)))\n",
    "    if RBAC121_lang.count('en') == len(RBAC121_lang):\n",
    "        translation_ready = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the full translation to .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = join('Regulations', 'RBAC121_sections_en.xlsx')\n",
    "df = pd.DataFrame({'title':titles, 'requirement':requirements, 'translation':RBAC121_en})\n",
    "df.to_excel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
